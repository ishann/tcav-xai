{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Figure out which examples googlenet gets right, and which ones it gets wrong from the test set\n",
    "2. Use TCAV to generate explanations for the wrong ones\n",
    "3. Analyze the explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembling concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating concepts: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:04<00:00,  5.30it/s]\n",
      "Creating Random concepts: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 394.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# ..........torch imports............\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "# .... Captum imports..................\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.concept import TCAV\n",
    "from captum.concept._utils.common import concepts_to_str\n",
    "\n",
    "# .... Local imports..................\n",
    "from joblib import load, dump\n",
    "\n",
    "from HierarchicalExplanation import HierarchicalExplanation\n",
    "from generate_data.hierarchy import Hierarchy\n",
    "from utils import assemble_all_concepts_from_hierarchy, assemble_random_concepts, generate_experiments\n",
    "from utils import load_image_tensors, transform, plot_tcav_scores, assemble_scores, get_pval, show_boxplots\n",
    "\n",
    "# Load Hierarchy\n",
    "HIERARCHY_JSON_PATH = 'generate_data/hierarchy.json'\n",
    "HIERARCHY_WORDNET_PATH = 'generate_data/wordnet_labels.txt'\n",
    "IMAGENET_IDX_TO_LABELS = 'generate_data/imagenet1000_clsidx_to_labels.txt'\n",
    "h = Hierarchy(json_path=HIERARCHY_JSON_PATH, wordnet_labels_path=HIERARCHY_WORDNET_PATH,\n",
    "              imagenet_idx_labels_path=IMAGENET_IDX_TO_LABELS)\n",
    "\n",
    "###################################################\n",
    "# Assemble Concepts\n",
    "# Let's assemble concepts into Concept instances using Concept class and concept images stored in `concepts_path`.\n",
    "###################################################\n",
    "\n",
    "# concepts_path = \"/home/devvrit/ishann/data/captum/tcav/concepts\"\n",
    "concepts_path = \"../data\"\n",
    "\n",
    "# Assemble non-random concepts\n",
    "concepts = assemble_all_concepts_from_hierarchy(h=h, num_images=100, concepts_path=concepts_path,\n",
    "                                                recreate_if_exists=True)  # Only 100 images for testing, can increase later\n",
    "\n",
    "# Assemble all random concepts\n",
    "random_concepts = assemble_random_concepts(concepts_path=concepts_path)\n",
    "\n",
    "\n",
    "# Defining GoogleNet Model\n",
    "model = torchvision.models.googlenet(pretrained=True)\n",
    "model = model.eval()\n",
    "layers=['fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010516643524169922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 18,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa160d1f25e84169ae253152c7f41ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Figure out which examples googlenet gets right, and which ones it gets wrong from the test set\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "data_path = '../data'\n",
    "IMAGENET_IDX_TO_LABELS = 'generate_data/imagenet1000_clsidx_to_labels.txt'\n",
    "with open(IMAGENET_IDX_TO_LABELS, 'r') as f:\n",
    "    idx2label = json.load(fp=f)\n",
    "\n",
    "class_name = 'Siberian husky'\n",
    "class_idx = h.imagenet_label2idx[class_name]\n",
    "wrong_count = 1000\n",
    "\n",
    "path = os.path.join(data_path, class_name)\n",
    "filenames = glob.glob(path + '/*.JPEG')\n",
    "correct_files = []\n",
    "wrong_files = []\n",
    "for i, filename in tqdm.notebook.tqdm(enumerate(filenames)):\n",
    "    if len(wrong_files) >= wrong_count:\n",
    "        break\n",
    "\n",
    "    img = transform(Image.open(filename).convert('RGB'))\n",
    "    img_batch = torch.unsqueeze(img, 0)\n",
    "    pred = model(img_batch)\n",
    "    if torch.argmax(pred) != class_idx:\n",
    "        wrong_files.append(filename)\n",
    "    else:\n",
    "        correct_files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files into tensors\n",
    "def load_image_tensors_from_list(list_images, do_transform=True, count=100):\n",
    "\n",
    "    tensors = []\n",
    "    for i, filename in enumerate(list_images):\n",
    "        if i >= count:\n",
    "            break\n",
    "\n",
    "        img = Image.open(filename).convert('RGB')\n",
    "        tensors.append(transform(img) if do_transform else img)\n",
    "        \n",
    "    return torch.stack(tensors)\n",
    "\n",
    "class_images_correct = load_image_tensors_from_list(correct_files, count=100)\n",
    "class_images_wrong = load_image_tensors_from_list(wrong_files, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'level_name': 'entity', 'children': [('equipment', tensor(0.4858)), ('geological formation', tensor(-0.0154)), ('organism', tensor(0.1385)), ('random_0', tensor(-0.5575))], 'pval': 0.6078544147126332}, {'level_name': 'organism', 'children': [('canine', tensor(0.0014)), ('feline', tensor(0.1746)), ('random_1', tensor(-0.0894))], 'pval': 0.784246780077577}, {'level_name': 'canine', 'children': [('white wolf', tensor(-0.0280)), ('dog', tensor(0.0639)), ('random_2', tensor(-0.0229))], 'pval': 0.0008236621685874774}, {'level_name': 'dog', 'children': [('golden retriever', tensor(0.0135)), ('dalmatian', tensor(0.1094)), ('Siberian husky', tensor(0.1251)), ('random_3', tensor(-0.1142))], 'pval': 0.13241210533018588}]\n",
      "The input is predicted to be a(n) Siberian husky (p-value: 0.1324).\n",
      "It is predicted to be a(n) Siberian husky because it is a dog.\n",
      "It is a(n) Siberian husky because out of all dogs, Siberian husky has the highest score among sub-classes:  (p-value: 0.1324)\n",
      "Class Name \t\t Score\n",
      "golden retriever \t\t 0.0135\n",
      "dalmatian \t\t 0.1094\n",
      "Siberian husky \t\t 0.1251\n",
      "random_3 \t\t -0.1142\n",
      "\n",
      "It is predicted to be a(n) dog because it is a canine.\n",
      "It is a(n) dog because out of all canines, dog has the highest score among sub-classes:  (p-value: 0.0008)\n",
      "Class Name \t\t Score\n",
      "white wolf \t\t -0.0280\n",
      "dog \t\t 0.0639\n",
      "random_2 \t\t -0.0229\n",
      "\n",
      "It is predicted to be a(n) canine because it is a organism.\n",
      "It is a(n) canine because out of all organisms, canine has the highest score among sub-classes:  (p-value: 0.7842)\n",
      "Class Name \t\t Score\n",
      "canine \t\t 0.0014\n",
      "feline \t\t 0.1746\n",
      "random_1 \t\t -0.0894\n",
      "\n",
      "It is predicted to be a(n) organism because it is a entity.\n",
      "It is a(n) organism because out of all entitys, organism has the highest score among sub-classes:  (p-value: 0.6079)\n",
      "Class Name \t\t Score\n",
      "equipment \t\t 0.4858\n",
      "geological formation \t\t -0.0154\n",
      "organism \t\t 0.1385\n",
      "random_0 \t\t -0.5575\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explain the right and wrong predictions\n",
    "he = HierarchicalExplanation(h=h, model=model, layer='fc', n_steps=5, load_save=False)\n",
    "\n",
    "# Right\n",
    "explanations = he.explain(input_tensors=class_images_correct, input_class_name=class_name, input_idx=class_idx, get_concepts_from_name=lambda x: concepts[x] if x in concepts else random_concepts[int(x.replace(\"random_\", \"\"))])\n",
    "print(explanations)\n",
    "long_form = he.long_form_explanations(explanations, \"Siberian husky\")\n",
    "print(long_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'level_name': 'entity', 'children': [('equipment', tensor(-0.0639)), ('geological formation', tensor(-0.0089)), ('organism', tensor(0.3964)), ('random_0', tensor(-0.3014))], 'pval': 0.004377852706947431}, {'level_name': 'organism', 'children': [('canine', tensor(0.8123)), ('feline', tensor(0.0281)), ('random_1', tensor(-0.4640))], 'pval': 0.052579513790523294}, {'level_name': 'canine', 'children': [('white wolf', tensor(0.1330)), ('dog', tensor(0.4865)), ('random_2', tensor(-0.3182))], 'pval': 0.1241489849560697}, {'level_name': 'dog', 'children': [('golden retriever', tensor(-0.0616)), ('dalmatian', tensor(-0.1182)), ('Siberian husky', tensor(0.5731)), ('random_3', tensor(-0.2777))], 'pval': 0.00036013454419289275}]\n",
      "The input is predicted to be a(n) Siberian husky (p-value: 0.0004).\n",
      "It is predicted to be a(n) Siberian husky because it is a dog.\n",
      "It is a(n) Siberian husky because out of all dogs, Siberian husky has the highest score among sub-classes:  (p-value: 0.0004)\n",
      "Class Name \t\t Score\n",
      "golden retriever \t\t -0.0616\n",
      "dalmatian \t\t -0.1182\n",
      "Siberian husky \t\t 0.5731\n",
      "random_3 \t\t -0.2777\n",
      "\n",
      "It is predicted to be a(n) dog because it is a canine.\n",
      "It is a(n) dog because out of all canines, dog has the highest score among sub-classes:  (p-value: 0.1241)\n",
      "Class Name \t\t Score\n",
      "white wolf \t\t 0.1330\n",
      "dog \t\t 0.4865\n",
      "random_2 \t\t -0.3182\n",
      "\n",
      "It is predicted to be a(n) canine because it is a organism.\n",
      "It is a(n) canine because out of all organisms, canine has the highest score among sub-classes:  (p-value: 0.0526)\n",
      "Class Name \t\t Score\n",
      "canine \t\t 0.8123\n",
      "feline \t\t 0.0281\n",
      "random_1 \t\t -0.4640\n",
      "\n",
      "It is predicted to be a(n) organism because it is a entity.\n",
      "It is a(n) organism because out of all entitys, organism has the highest score among sub-classes:  (p-value: 0.0044)\n",
      "Class Name \t\t Score\n",
      "equipment \t\t -0.0639\n",
      "geological formation \t\t -0.0089\n",
      "organism \t\t 0.3964\n",
      "random_0 \t\t -0.3014\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wrong\n",
    "explanations = he.explain(input_tensors=class_images_wrong, input_class_name=class_name, input_idx=class_idx, get_concepts_from_name=lambda x: concepts[x] if x in concepts else random_concepts[int(x.replace(\"random_\", \"\"))])\n",
    "print(explanations)\n",
    "long_form = he.long_form_explanations(explanations, \"Siberian husky\")\n",
    "print(long_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'level_name': 'entity', 'children': [('equipment', tensor(0.0693)), ('geological formation', tensor(0.4898)), ('organism', tensor(0.1743)), ('random_0', tensor(-0.4526))], 'pval': 0.6374294499898574}, {'level_name': 'organism', 'children': [('canine', tensor(0.0435)), ('feline', tensor(-0.0337)), ('random_1', tensor(-0.0126))], 'pval': 0.02403836271634667}, {'level_name': 'canine', 'children': [('white wolf', tensor(-0.0413)), ('dog', tensor(0.1524)), ('random_2', tensor(-0.0399))], 'pval': 1.3732571329707236e-05}, {'level_name': 'dog', 'children': [('golden retriever', tensor(0.0345)), ('dalmatian', tensor(0.1032)), ('Siberian husky', tensor(0.0183)), ('random_3', tensor(-0.0708))], 'pval': 0.9408930790868546}]\n",
      "The input is predicted to be a(n) Siberian husky (p-value: 0.9409).\n",
      "It is predicted to be a(n) Siberian husky because it is a dog.\n",
      "It is a(n) Siberian husky because out of all dogs, Siberian husky has the highest score among sub-classes:  (p-value: 0.9409)\n",
      "Class Name \t\t Score\n",
      "golden retriever \t\t 0.0345\n",
      "dalmatian \t\t 0.1032\n",
      "Siberian husky \t\t 0.0183\n",
      "random_3 \t\t -0.0708\n",
      "\n",
      "It is predicted to be a(n) dog because it is a canine.\n",
      "It is a(n) dog because out of all canines, dog has the highest score among sub-classes:  (p-value: 0.0000)\n",
      "Class Name \t\t Score\n",
      "white wolf \t\t -0.0413\n",
      "dog \t\t 0.1524\n",
      "random_2 \t\t -0.0399\n",
      "\n",
      "It is predicted to be a(n) canine because it is a organism.\n",
      "It is a(n) canine because out of all organisms, canine has the highest score among sub-classes:  (p-value: 0.0240)\n",
      "Class Name \t\t Score\n",
      "canine \t\t 0.0435\n",
      "feline \t\t -0.0337\n",
      "random_1 \t\t -0.0126\n",
      "\n",
      "It is predicted to be a(n) organism because it is a entity.\n",
      "It is a(n) organism because out of all entitys, organism has the highest score among sub-classes:  (p-value: 0.6374)\n",
      "Class Name \t\t Score\n",
      "equipment \t\t 0.0693\n",
      "geological formation \t\t 0.4898\n",
      "organism \t\t 0.1743\n",
      "random_0 \t\t -0.4526\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explain images from another class entirely\n",
    "husky_idx = h.imagenet_label2idx[class_name]\n",
    "\n",
    "\n",
    "class_images = load_image_tensors(class_name, root_path=concepts_path, transform=False, count=100)\n",
    "class_tensors = torch.stack([transform(img) for img in class_images])\n",
    "class_idx = h.imagenet_label2idx[class_name]\n",
    "\n",
    "\n",
    "explanations = he.explain(input_tensors=class_tensors, input_class_name='Siberian husky', input_idx=husky_idx, get_concepts_from_name=lambda x: concepts[x] if x in concepts else random_concepts[int(x.replace(\"random_\", \"\"))])\n",
    "print(explanations)\n",
    "long_form = he.long_form_explanations(explanations, \"Siberian husky\")\n",
    "print(long_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output you provided is from a trained GoogLeNet model that has been given images of a valley (the landform) and asked to explain how it is a Siberian husky. The model uses a hierarchical classification system, in which it first assigns scores to different classes at the highest level of the hierarchy, then repeats the process for sub-classes within those classes, and so on until it reaches the final prediction.\n",
    "\n",
    "In this case, the model predicts that the input images are of a Siberian husky with a low degree of confidence (p-value: 0.9409). The model arrives at this prediction by first classifying the input as an organism, then a canine, then a dog, and finally as a Siberian husky. For each classification, the model assigns scores to different sub-classes within that category, and the sub-class with the highest score is chosen as the final prediction.\n",
    "\n",
    "For example, within the category of canines, the model assigns a score of 0.0435 to the sub-class of canine and a score of -0.0337 to the sub-class of feline. Since the score for canine is higher, it is chosen as the final prediction for that category. This process is repeated for each classification until the final prediction of Siberian husky is reached.\n",
    "\n",
    "However, the high p-values for each classification indicate that the model is not very confident in its predictions. A p-value of 0.9409 for the final prediction of Siberian husky is quite high, which means that there is a high probability that the observed result (the prediction of a Siberian husky) occurred by chance. This indicates that the model is not very confident in its prediction, and the result should be interpreted with caution.\n",
    "\n",
    "Overall, this output shows how the trained GoogLeNet model uses a hierarchical classification system to arrive at a prediction, but the high p-values suggest that the model is not very confident in its final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
